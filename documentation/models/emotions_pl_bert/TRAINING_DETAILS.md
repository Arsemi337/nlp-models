# Training details

All the trainings are fine-tuning of ***dkleczek/bert-base-polish-uncased-v1*** model. The used dataset is available in
the [dataset .json file](../../../data/polish_translated/sarcasm/emotions_dataset_pl.json).
Originally it consists of 40000 data samples.

| Training no. | Data samples | Train set % | Val set % | Test set % | Batch size | Epochs | Best epoch |         Fitting time         | Train accuracy | Train loss | Val accuracy | Val loss | Test accuracy | Test loss |               Accuracy figure               |               Loss figure               |               Confusion matrix                |                                Notes                                 |
|:------------:|:------------:|:-----------:|:---------:|:----------:|:----------:|:------:|:----------:|:----------------------------:|:--------------:|:----------:|:------------:|:--------:|:-------------:|:---------:|:-------------------------------------------:|:---------------------------------------:|:---------------------------------------------:|:--------------------------------------------------------------------:|
|      1       |    9,018k    |     80%     |    10%    |    10%     |     8      |   10   |     3      |   14min 23s (***Colab***)    |     0.9206     |   0.2381   |    0.8348    |  0.5188  |    0.8359     |  0.5687   | [figure](./figures/training_1_accuracy.png) | [figure](./figures/training_1_loss.png) | [figure](./figures/training_1_confmatrix.png) |                         Equalized but small                          |
|      2       |     40k      |     80%     |    10%    |    10%     |     8      |   10   |     1      |   37min 02s (***Colab***)    |     0.8046     |   0.5450   |    0.8475    |  0.3800  |    0.8487     |  0.4046   | [figure](./figures/training_2_accuracy.png) | [figure](./figures/training_2_loss.png) | [figure](./figures/training_2_confmatrix.png) |                         Unequalized but full                         |
|      3       |     40k      |     80%     |    10%    |    10%     |     16     |   10   |     2      |   37min 18s (***Colab***)    |     0.8930     |   0.3074   |    0.8680    |  0.4139  |    0.8670     |  0.4244   | [figure](./figures/training_3_accuracy.png) | [figure](./figures/training_3_loss.png) | [figure](./figures/training_3_confmatrix.png) |                          Equalized and full                          |
|      4       |     40k      |     80%     |    10%    |    10%     |     8      |   10   |     3      |   52min 49s (***Colab***)    |     0.9082     |   0.2610   |    0.8692    |  0.4334  |    0.8662     |  0.4134   | [figure](./figures/training_4_accuracy.png) | [figure](./figures/training_4_loss.png) | [figure](./figures/training_4_confmatrix.png) |                          Equalized and full                          |
|      5       |     40k      |     80%     |    10%    |    10%     |     8      |   10   |     1      | 20min 18s (***RTX 3070Ti***) |     0.8036     |   0.5872   |    0.8662    |  0.4027  |    0.8615     |  0.4136   | [figure](./figures/training_5_accuracy.png) | [figure](./figures/training_5_loss.png) | [figure](./figures/training_5_confmatrix.png) | Dataset shuffled with seed 42 for same training/validation/test data |

